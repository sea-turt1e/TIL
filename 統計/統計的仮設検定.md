# 帰無仮説、対立仮説
- 帰無仮説と対立仮説を立てる。対立仮説が本来示したいこと。
- p値
  - 帰無仮説が正しいと仮定した時、観測されたデータが得られる確率
  - 一般的にp < 0.05ならばキム仮説が棄却され、「差がある」（対立仮説が正しい）となる。つまり「有意である」となる。

# A/Bテスト
## 比率の差の検定（Proportion z-test）
- A/Bテストで最も一般的な方法
![alt text](image/image-1.png)

- 例: LLMのモデルA vs モデルBの正解率比較:
  - モデルA: 100サンプル中75正解（75%）
  - モデルB: 100サンプル中60正解（60%）
![alt text](image/image-2.png)

## t検定(Two sample t-test)
- 連続値の平均を比較する場合（例: 評価スコア1-5点の平均）
- サンプルサイズが大きければ、比率の比較にも使える
![alt text](image/image.png)

## カイ2乗検定
- 2x2のカテゴリカルデータ（=分割表）の独立性の検定
![alt text](<image/スクリーンショット 2026-02-09 14.19.40.png>)

# Bootstrap と Permutation Test
## Permutation Test（並び替え検定）
- 基本的な考え方
  - 「2つのグループが本当に同じ分布から来ているなら、ラベルをシャッフルしても結果は変わらないはず」
- 手順
  - 実際のデータで統計量（平均の差など）を計算
  - グループラベル（A/B）をランダムにシャッフル
  - シャッフル後のデータで統計量を計算
  - これを数千〜数万回繰り返す
  - 実際の統計量が、シャッフル分布の中でどれだけ極端か（p値）を計算

## Bootstrap Test
- 基本的な考え方
​  - 「標本から復元抽出（リサンプリング）を繰り返すことで、統計量の分布を推定する」
- 手順
  - 元のデータから復元抽出でリサンプル
  - リサンプルで統計量を計算
  - これを数千〜数万回繰り返す
  - 統計量の分布を作成
  - 信頼区間を計算、またはp値を推定