# 日本語・多言語固有のポイント
## SentencePiece
トークン数を先に決めておいて、その数に分割するアルゴリズム

### BPE(Byte Pair Encoding)
- 頻繁に隣り合うペアを繰り返してマージ
- 語彙数が増えるほど、長い単位でトークン化される。
```
① 初期状態: 全文字を個別のトークンにする
   "猫が好き" → ["猫", "が", "好", "き"]

② 最も頻繁に隣接するペアをマージ
   コーパス全体で "好き" が最も多く隣接
   → "好き" を1つのトークンにする
   ["猫", "が", "好き"]

③ 語彙数が目標に達するまで繰り返す
   "猫が" も頻繁 → マージ
   ["猫が", "好き"]
```

### Unigram
各トークンの出現頻度の確率に合わせて、最終的な語彙を決める
- BPEとの違い
  - BPEは「下から積み上げる（=マージ）」。
  - Unigramは「上から削る」アプローチ
```
① 大きな語彙（数万〜数十万）を初期設定
② 各トークンの「存在しても性能が下がらないもの」を削除
③ 目標語彙数まで繰り返す
```

- 同じ文字列でも複数の分割候補があり、確率で選ぶのがUnigramの特徴
- 学習時にサンプリング（確率に従って複数候補を使う）ことで、モデルの汎化性が上がる
- どのトークン単位で分割するかと、各確率が互いに決め合う
```
"東京都知事" の分割候補:

候補1: ["東京", "都", "知事"]  確率: 0.7
候補2: ["東京都", "知事"]     確率: 0.2
候補3: ["東", "京都", "知事"] 確率: 0.08
候補4: ["東京都知事"]         確率: 0.02

→ 最も確率が高い候補1を選択
```
- 語彙にない単語が来た場合、Byte列に分解して（Byte Fallback）、語彙の中にあるByte列で表現

## 日本語LLMのベンチマーク
```
日本語ベンチマーク
  ├── JGLUE（最もよく使われる統合ベンチマーク）
  ├── NLI系（自然言語推論に特化）
  ├── QA系（質問応答に特化）
  ├── 生成評価系（LLM時代の評価）
  └── 統合評価フレームワーク（複数データセットをまとめて評価）
```

### JGLUE
- GLUEの日本語版
- 含まれるタスク一覧

| データセット         | タスク種別    | 内容                             |
| -------------- | -------- | ------------------------------ |
| MARC-ja        | 文章分類     | Amazonレビューのポジティブ/ネガティブ分類（2値）   |
| JCoLA          | 文章分類     | 日本語の文が文法的に正しいかどうかの判定（東大・大関研作成） |
| JSTS           | 文ペア分類    | 2文の意味的類似度をスコアリング（0〜5）          |
| JNLI           | 文ペア分類    | 2文の関係が「含意/矛盾/中立」かを判定           |
| JSQuAD         | 質問応答（QA） | Wikipedia記事を読んで質問に答える（機械読解）    |
| JCommonsenseQA | 質問応答（QA） | 常識知識に基づく4択問題                   |


