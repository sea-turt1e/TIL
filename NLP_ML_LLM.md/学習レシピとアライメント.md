# 学習レシピとアライメント

## Pretrain: 大規模コーパス構築
- LLMのデータソースは複数のソースが使われる。
- 典型的な構成は以下
| ソース                | 特徴          | 比率（目安） |
| ------------------ | ----------- | ------ |
| Common Crawl / Web | 最大規模、ノイズ多い  | 50〜70% |
| Wikipedia          | 高品質、多様なトピック | 5〜10%  |
| 書籍・論文              | 長文・高品質      | 10〜20% |
| コード (GitHub)       | 推論能力向上に寄与   | 5〜10%  |
| ニュース・Q&A           | 事実性が高い      | 5〜10%  |

### Dedup(De-duplication) 重複削除
- 重複データを削除しないとモデルが特定のパターンを丸暗記/学習する恐れがある
- 3レベルのdedupがある
  - 完全一致（Extract）
    - Hash（MD5/SHA）で一致を検出
  - 近似一致（Fuzzy）
    - MniHash + LSH（局所性鋭敏型ハッシュ）
    - Jaccard類似度を計算し、閾値以上なら削除
  - 意味的一致（Semantic）
    - 文書埋め込み -> コサイン類似度で比較
    - 埋め込みが近ければ一方を削除
- RefinedWebの事例: CommonCrawlの約5兆トークンから90%を削除し、高品質な500億トークンを抽出。「引き算の哲学」が重要

### フィルタリング
#### ヒューリスティックフィルタ
```
① URL/ドメインフィルタ:
   スパム・アダルトサイトのドメインをブロックリストで除外

② 言語フィルタ:
   fastText/langdetect で日本語確率 < 0.8 のものを除外

③ テキスト長フィルタ:
   短すぎる文書（例: 50トークン以下）を除外
   短すぎる行が多い文書（ナビゲーションメニューなど）を除外

④ 記号比率フィルタ:
   記号・数字の割合が異常に高い文書を除外
   例: "!!!!!買って!!!! 5000円→500円!!!!" → 除外

⑤ 重複行フィルタ:
   同じ行が繰り返されている文書を除外
   例: フッターが大量コピーされたWebページ
```

#### モデルベースフィルタ（高精度・高コスト）
```
① 品質スコアリング:
   高品質文書（Wikipedia等）で学習した分類器で品質スコアを計算
   例: Kenlm perplexityが高すぎる文書は低品質として除外

② 有害コンテンツフィルタ:
   ヘイトスピーチ、差別的表現を分類モデルで除外

③ PII（個人情報）除去:
   電話番号、メールアドレス、住所などを正規表現 + NERで除去
```

#### 日本語固有のフィルタリング
```
- Unicode正規化（NFKC）: 全角・半角の統一
- 文字化けの除去: □□□ のような文字
- Ruby（ルビ）テキストの処理: HTMLから正しく抽出
- 縦書きテキストの変換
- 機種依存文字の処理
```

#### データミキシング比率の設計
単純にすべてのデータを混ぜるのではなく、比率を調整することが重要です:

```python
# データミキシングの例
dataset_weights = {
    "web": 0.60,        # CommonCrawl（日本語フィルタ済み）
    "wikipedia": 0.10,  # 日本語Wikipedia
    "books": 0.15,      # 書籍データ
    "code": 0.08,       # GitHub（日本語コメント付き）
    "qa": 0.07,         # Yahoo知恵袋、Stack Overflow
}
# 高品質ソースを過剰にサンプリング（Upsampling）することも有効
```

## SFT
- SFTは多様なタスクをカバーする必要あり
```
タスクカテゴリの例:

① 質問応答
   "東京の人口は？"

② 要約
   "以下の文章を3行に要約してください：..."

③ 創作・生成
   "桜をテーマにした俳句を作ってください"

④ コード生成
   "PythonでFizzBuzzを実装してください"

⑤ 翻訳
   "以下を英語に翻訳してください：..."

⑥ 推論・分析
   "AとBの違いを説明してください"

⑦ 指示に従う（命令型）
   "箇条書きで5つ挙げてください"

⑧ 安全性・拒否
   "この質問には答えられません、なぜなら..."
```
- タスクが偏ると、モデルが特定のタスクに過学習する。
