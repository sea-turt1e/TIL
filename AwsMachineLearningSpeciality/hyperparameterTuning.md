# ハイパーパラメータチューニング
- ハイパーパラメータの同時実行ジョブを減らすと、リソースの使用量とコストを抑える


### 1. 対数スケール（Logarithmic Scale）とは？  
対数スケールとは、パラメータの値を等間隔ではなく、対数（log）に基づいて分布させる方法です。  
機械学習のハイパーパラメータチューニングでは、値の範囲が広い場合に対数スケールを使うと、より効果的に探索できます。

#### 対数スケールの特徴
- 探索範囲が広い場合に有効（例：`0.0001` から `1.0` までの学習率）
- 指数的に影響するパラメータ（学習率、正則化係数など）に向いている
- 小さい値と大きい値の両方をバランスよく探索できる

#### 対数スケールの具体例
例えば、学習率（learning rate） を `0.0001` から `1.0` の間で探索するとします。

- 通常の線形スケール（Linear Scale）では `0.0001, 0.2000, 0.4000, 0.6000, 0.8000, 1.0000` というように均等に分布します。
- 対数スケール（Log Scale）を使うと、`0.0001, 0.001, 0.01, 0.1, 1.0` のように、値が指数的に増加します。

→ これにより、広い範囲の重要なポイントを効率よく試すことができます。

---

### 2. 逆対数スケール（Reverse Logarithmic Scale）とは？
逆対数スケールは、`0 <= x < 1.0` の範囲で対数スケールを適用する方法 です。  
通常の対数スケールは `0.0001` から `1.0` のように大きな範囲を探索しますが、逆対数スケールは `0` に近い値の探索を強調します。

#### 逆対数スケールの特徴
- 0 に近い範囲（0.0001 〜 1.0）のパラメータを調整したいときに使う
- 小さな値の変化が重要なパラメータ（ドロップアウト率、正則化係数など）に適している

#### 逆対数スケールの具体例
例えば、ドロップアウト率（dropout rate） を `0.001` から `1.0` の間で探索するとします。

- 通常の対数スケール だと `0.001, 0.01, 0.1, 1.0` のように分布。
- 逆対数スケール だと `0.99, 0.9, 0.5, 0.1, 0.01` のように、`1` に近い値がより多く試される。

→ これにより、0 に近い値がより細かく調整され、最適なパラメータを見つけやすくなります。

---

### 3. ウォームスタート（Warm Start）とは？
ウォームスタートとは、過去のハイパーパラメータチューニングの結果を活かして、新しいチューニングを行う方法 です。  
機械学習モデルを再学習する際、過去の経験を活かして、最適化を加速できます。

#### ウォームスタートの特徴
- 過去のチューニング結果を利用して、新しい最適解を素早く見つける
- 不要な試行を省略できるため、計算コストを削減
- 特にベイズ最適化（Bayesian Optimization）と相性が良い

#### ウォームスタートの具体例
例えば、以前のハイパーパラメータチューニングで以下の学習率の結果が得られたとします：

| 学習率 | 精度（Accuracy） |
|--------|---------------|
| 0.01   | 85%          |
| 0.1    | 80%          |
| 0.001  | 87%          |

次回のチューニングでは、0.001 に近い値（例: 0.0005, 0.002）を重点的に探索できます。

#### ウォームスタートがない場合
毎回ランダムに試行するため、過去の結果を無視して非効率的な探索になる可能性があります。

---

### まとめ
| 概念 | 説明 | 例 |
|------|------|----|
| 対数スケール（Log Scale） | パラメータ範囲を対数的に分布させる | 学習率（0.0001 ~ 1.0） |
| 逆対数スケール（Reverse Log Scale） | `0 <= x < 1.0` の範囲で対数スケールを適用 | ドロップアウト率（0.001 ~ 1.0） |
| ウォームスタート（Warm Start） | 過去のチューニング結果を活用して効率的に最適化 | 以前の学習率 0.001 が良かった場合、その周辺を再探索 |

→ これらを活用することで、ハイパーパラメータチューニングの精度と効率が向上します！ 🚀

## 学習率が異常に高いと
- 精度の変化が激しく、波うってしまう。

## データセットのクラス分布が不均衡である
- モデルの予測が特定のクラスに偏る（精度が低い、リコールやF1スコアが悪化する）が、「振動」ではなく「一貫したバイアス」になることが多いです

## データセットのシャッフリングは無効である
- データの並び順による偏りが生じ、学習がうまく進まない・収束しないことがあります。精度が周期的に変動することはありますが、典型的な「振動」とはやや異なります。

## バッチサイズが大きすぎる
- 収束が遅くなったり、汎化性能が低下したりしますが、精度が大きく「振動」する主原因にはなりません