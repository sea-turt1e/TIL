# StandardScaler
- 標準化を行うためのクラス
- データの平均を0、標準偏差を1に変換する

# normalizer
- 正規化を行うためのクラス

# 標準化、正規化の違い
- 標準化は平均を0、標準偏差を1に変換する
- 正規化はデータを0から1の範囲にスケーリングする

- 標準化の適用シナリオ
標準化は、特徴量が正規分布に近い場合や、アルゴリズムがデータの平均や分散に敏感な場合（例えば、線形回帰、ロジスティック回帰、サポートベクターマシンなど）に適しています。  
また、外れ値が存在し、それらに対してある程度の耐性を持たせたい場合にも有効です。
- 正規化の適用シナリオ
正規化は、データが固定範囲内に収まることが重要な場合（例えば、ニューラルネットワークの入力データとして）や、距離に基づくアルゴリズム（例えば、K-最近傍法やK-平均法）で使用される場合に適しています。

# Parquetデータ形式
- Parquetは、高速で効率的なデータストレージ形式の一つです。
- Parquetは、列指向のデータ形式であり、データを列ごとに格納することで、データの圧縮率を高め、データの読み取り速度を向上させることができます。

# AWS Batch
- AWS Batchは、大規模なバッチ処理ジョブを簡単に実行できるサービスです。
- AWS Batchを使用すると、コンピューティングリソースのプロビジョニングやスケーリングを自動化し、バッチ処理ジョブの実行を効率化することができます。

# Sockeye
- Sockeyeは、ニューラル機械翻訳のためのオープンソースのライブラリです。
- Sockeyeは、Seq2Seq（Sequence to Sequence）モデルを使用して、異なる言語間での翻訳を行うことができます。

# canary デプロイ方法論
- Canaryデプロイは、新しいバージョンのアプリケーションを一部のユーザーに展開し、問題がないことを確認した後、全体のユーザーに展開する方法です。

# VPC フローログ(VPC = Virtual Private Cloud)
- VPCフローログは、Amazon VPC（Virtual Private Cloud）内で発生するネットワークトラフィックに関するログデータを記録するための機能です。

# MLLib
- MLLibは、Apache Sparkの機械学習ライブラリです。
- MLLibを使用することで、分散環境での機械学習モデルのトレーニングや予測を行うことができます。

# Random Cut Forest
- Random Cut Forestは、異常検知や異常検出のためのアルゴリズムです。
- Random Cut Forestは、データの異常度を評価するために、ランダムなカットを使用してデータを分割し、異常度を計算します。
- Random Cut Forestは、大規模なデータセットに対して高速かつ効率的に異常検知を行うことができます。

# Athena
- Athenaは、SQLを使用してS3に保存されたデータをクエリするためのサービスです。
- データをathenaで分析し、quicksightで可視化できる
- データを圧縮すると安く運用できる
- アドホック（その場限りの）SQLクエリを実行するのに適している。

# 交差エントロピーlogloss
- 交差エントロピー（Cross Entropy）は、2つの確率分布の違いを表す指標です。
- 交差エントロピーは、2つの確率分布がどれだけ異なるかを示す値であり、異なる確率分布の間の距離を測るために使用されます。
- loglossは、交差エントロピーの一種であり、2つの確率分布の間の距離を計算するために使用されます。

# グリッドサーチ
- グリッドサーチは、ハイパーパラメータの最適な値を見つけるための手法です。

# ターゲットラベル
Sagemakerではターゲットラベルを最初の列に配置する必要がある。

# 事前確率分布
- 事前確率分布は、事前に与えられた情報に基づいて、事象が発生する確率を表す確率分布です。

# モンテカルロシュミレーション
- モンテカルロシュミレーションは、確率的な手法を使用して、複雑な問題やシステムの振る舞いをモデル化する手法です。


# 割合問題
割合系の問題は英語表示をして確かめたほうがよさそう

# AWS DeepLens
- AWS DeepLensは、ディープラーニングモデルを使用して、画像やビデオデータを処理するためのデバイスです。
- リアルタイムが特徴

# Horovod 分散学習
- Horovodは、分散学習のためのフレームワークです。
- Horovodを使用することで、複数のGPUや複数のマシンを使用して、大規模なデータセットでの学習を行うことができます。
- Horovodは、TensorFlowやPyTorchなどのディープラーニングフレームワークと統合されており、分散学習を簡単に実装することができます。

# ネットワークサイズを下げる
- ネットワークサイズを下げることで、モデルの複雑さを減らし、過学習を防ぐことができます。

#　管理方法
## AWS Step Functions
- サーバーレスのサービスを順番づけて管理するのに向いてる

## Managed Workflows for Apache Airflow(MWAA)
- 複雑なデータ処理や高度のタスクをオーケストレーション（複数のサービスを調整して実行）できる

## Amazon SQSとAWS Lambda
上2つより柔軟性に富むが、開発は多くなる 

## Sagemakerへの入力形式
- データセットはCSV、JSON、LibSVM、Parquet、RecordIOなどの形式で提供することができます。
- sagemaker seq2seqはRecordIO-Protobuf形式と整数トークン([[301, 1021, ...]])を使用する。
  - RecordIO-Protobuf形式は、バイナリデータをシリアライズするためのフォーマットで、高速で効率的なデータの読み書きを可能にします。

## sagemakerの要求
- 8080ポートで/invocations, /pingのエンドポイントを提供する必要がある
  - /invocations: 推論リクエストを受け取り、推論結果を返すエンドポイント
    - invocations: 呼び出し
  - /ping: ヘルスチェックを行うためのエンドポイント
  - 8080ポートは80の代替（proxy）として利用される。1023版以下はwell-known portsとして予約されているため、80の代替として8080が利用されることが多い。
  - モデル成果物はtar形式で提供する必要がある
  - ping応答要件は2秒未満

## データサイエンスのグラフ把握
季節性とトレンドの両方の把握が必要
- 季節性
  - 季節性(season)は、データが特定の季節や時期に従って変動する傾向を指します。
- トレンド
  - トレンド(trend)は、データが時間の経過とともに増加または減少する傾向を指します。

## Amazon SES
- Amazon SES（Simple Email Service）は、メールの送信と受信を簡単に管理できるサービスです。

## Amazon SNS
- Amazon SNS（Simple Notification Service）は、メッセージの配信を簡単に管理できるサービスです。

## Sparkタスクノード
- Sparkタスクノードは、Sparkジョブのタスクを実行するノードです。
- タスクノードは、データの分散処理や並列処理を行い、ジョブの実行を効率化します。
- EC2スポットインスタンスを使用してSparkタスクノードをプロビジョニングすることができます。
  - プロビジョニング: システムやサービスを提供するために必要なリソースを割り当てること
  - EC2スポットインスタンス: AWSのサービスで、AWSのデータセンター内で実行される仮想サーバーのこと

## マネージドスポットトレーニング
- マネージドスポットトレーニングは、EC2スポットインスタンスを使用して、機械学習モデルのトレーニングを効率化するためのサービスです。
- マネージドスポットトレーニングを使用することで、コストを削減しながら、機械学習モデルのトレーニングを行うことができます。

## タスクノード、コアノード、マスターノード
- タスクノード: ジョブのタスクを実行するノード
- コアノード: データの処理やストレージを担当するノード  
- マスターノード: クラスタ全体の管理を担当するノード
- マスターノードとコアノードはデータ損失のリスクがあるため、スポットインスタンスはだめ。
- タスクノードは処理のみを行うため、スポットインスタンスを使用しても問題ない。

## Amazon Lex
- 音声->テキストへの変換と会話ロジックの処理の両方を行う
- 音声、テキスト両方の処理が可能

## Amazon Polly
- テキスト->音声への変換を行う

## BlazingText
- CBOW（Continuous Bag of Words）とSkip-gramの2つのアルゴリズムを使用して、単語のベクトル表現を学習する
  - CBOW: 周囲の単語から中央の単語を予測する
  - Skip-gram: 中央の単語から周囲の単語を予測する
  - 単語の順序は無視される

## K近傍法(K-Nearest Neighbors) KNN
- K近傍法は、分類や回帰のための教師あり学習アルゴリズムです。
- K近傍法は、新しいデータポイントを、最も近いK個のトレーニングデータポイントの多数決で分類する方法です。
- K近傍法は、データが線形分離可能でない場合や、非線形な関係を持つ場合に有効です。

## K-means法(K-means Clustering)
- K-means法は、クラスタリングのための非階層的なアルゴリズムです。
- K-means法は、データをK個のクラスタに分割するためのアルゴリズムであり、各クラスタの中心を見つけることを目的とします。
- K-means法は、クラスタの数Kを事前に指定する必要があります。
- K-means++
  - K-means法の初期化を改善するための手法であり、初期クラスタ中心をより適切に選択することで、収束速度を向上させることができます。
  - K-means++は、初期クラスタ中心をランダムに選択するのではなく、データポイント間の距離を考慮して選択します。
  - K-means++は、K-means法の初期化を改善するための手法であり、初期クラスタ中心をより適切に選択することで、収束速度を向上させることができます。

## Random Cut Forest
- Random Cut Forestは、異常検知や異常検出のためのアルゴリズムです。
- Random Cut Forestは、データの異常度を評価するために、ランダムなカットを使用してデータを分割し、異常度を計算します。

## 学習率の上げ下げ
- 学習率を上げたときに精度が下がる場合
  - 最小値を超えてしまい、最適解に収束できない場合がある
- 学習率を下げ過ぎた場合
  - 局所最適値に落ちてしまい、最適解に収束できない場合がある

## NACL(Network Access Control List)
- NACLは、VPC内のサブネットに対するトラフィックの許可や拒否を制御するためのセキュリティグループのようなものです。
- NACLは、サブネットレベルで設定され、インバウンドとアウトバウンドのトラフィックを制御します。

## サブネット
- サブネットは、VPC内のIPアドレスの範囲を定義するためのネットワークセグメントです。
- サブネットは、VPC内のリソースをグループ化し、セキュリティやネットワークの管理を行うために使用されます。
- ネットワークセグメント: ネットワークを論理的に分割すること

## Amazon QuickSight
- ML Ingisthgsと統合されている
- 可視化と予測の両方ができる。**予測がもできる**大事！
- 時系列データの将来の予測ができる
- BI向けデータ分析、可視化ツール

## AWS SPICE(Super-fast, Parallel, In-memory Calculation Engine)
- QuickSightのデータセットを高速に処理するためのエンジン


## Amazon Machine Learning Insights
- AWSのBIツール
- QuickSithtに搭載された学習機能
- 専門家である必要がない
- RCFを使った異常検出
- 数値予測
- 自動ナラティブ生成（自動的にレポートを生成）

## Tableau
- BIツール

## VPCエンドポンと
パブリックなインターネットではなく、プライベートなネットワークの通信を可能にする

## Dircet Connect
オンプレとのダイレクトなコネクションを確立する

## Sagemeaker Data Wrangler(Wrangler=口論する人、カウボーイ。作業者)
- データの前処理を行うためのツール
- データのクリーニング、変換、結合などの作業を行うことができます。

## Amazon Forecast
- Amazon Forecastは、時系列データを使用して予測モデルを構築するためのサービスです。
- Amazon Forecastを使用することで、需要予測、在庫管理、販売予測などの問題に対して、高精度な予測モデルを構築することができます。
- 天気予報（weather forecast）のようなもの
- 新規には利用できない。（サービス終了）
- パラメータ
  - PerformAutoML
    - 自動的に最適なモデルを選択する
    - デフォルトはFalse
  - ForecastFrequency
    - 予測の頻度を指定する
    - 例: "D"（日次）、"H"（時間）、"M"（月次）など
  - ForecastHorizon
    - 予測の期間を指定する
    - 例: 10（10日間の予測）
  - PerformHPO
    - 自動的にハイパーパラメータの最適化を行う
    - デフォルトはFalse
  - FeaturizationMethodName
    - 特徴量の生成方法を指定する
    - fillingにすると、欠損値を補完する

## Sagemaker Feature Store
- Sagemaker Feature Storeは、特徴量を管理するためのサービスです。
- Sagemaker Feature Storeを使用することで、特徴量のバージョン管理や再利用、共有などを行うことができます。
- データの外れ値の削除や顕出はできない

## Sagemeaker Clarify
- バイアスの検出やモデルの公平性を評価するためのツール
- モデルの透明性や公平性を確保できる
- バイアスの検出ができる
- どうやってバイアスを検出するか？
  - データの偏りを検出する
  - モデルの予測結果に偏りがあるかどうかを検出する

## Model Monitor
- モデルのパフォーマンスを監視するためのツール
- 推論中に品質の問題を検出して警告してくれる

## SageMaker HPO (Hyperparameter Optimization)
- ハイパーパラメータの最適化を行うためのツール
- ハイパーパラメータの探索空間を定義し、最適なハイパーパラメータを見つけるための探索を行うことができます。
- max_jobs
  - 最大で実行されるジョブの数を指定します。
- max_parallel_jobs
  - 同時に実行されるジョブの数を指定します。
  - max_jobsとの違いは何か？
    - max_jobsは、最大で実行されるジョブの数を指定します。
    - max_parallel_jobsは、同時に実行されるジョブの数を指定します。
- 早期停止ができ、精度が高まらない場合はジョブ停止ができる

## Amazon Redshift
- Amazon Redshiftは、データウェアハウスサービスです。
- Amazon Redshiftを使用することで、大規模なデータセットを高速にクエリすることができます。
- データウェアハウス: ビジネスインテリジェンス（BI）やデータ分析のためにデータを集約、統合、分析するためのデータベース

## Amazon Athena
- Amazon Athenaは、SQLを使用してS3に保存されたデータをクエリするためのサービスです。
- Amazon Athenaを使用することで、データを簡単にクエリして分析することができます。

## Redshft VS Athena
- Redshiftはデータウェアハウスサービスであり、大規模なデータセットを高速にクエリすることができます。
- Athenaは、SQLを使用してS3に保存されたデータをクエリするためのサービスであり、データを簡単にクエリして分析することができます。
- Redshiftはいろいろとでき、Athenaはクエリのみ

## インスタンスの種類
- P3: GPUを使用したインスタンス
- M5: CPUベースの汎用インスタンス
- T3: CPUベースの低コストインスタンス
- R5: メモリを大量に消費。GPUなし

## Amazon Elastic Inference
- M5などのCPUベースのインスタンスに必要な分だけGPUを追加することができる

## XGBoost1.2
- GPUのサポートが追加された

## EMRFS(EMR File System)
- EMRFSは、Amazon EMR（Elastic MapReduce）で使用されるファイルシステムです。
- EMRFSを使用することで、Amazon S3に保存されたデータをHadoopやSparkなどの分散処理フレームワークから直接アクセスすることができます。
- Hadoop file system(HDFS) APIの実装。

## HDFS(Hadoop Distributed File System)
- HDFSは、Hadoopの分散ファイルシステムです。
- HDFSは、大規模なデータセットを複数のノードに分散して保存し、高い信頼性とスケーラビリティを提供します。

## 分位ビニング(Quantile Binning)
- 分位ビニングは、データを複数のビンに分割する方法です。
- 外れ値の影響を軽減するために使用される
- 分位ビニングは、データを等しいサイズのビンに分割するのではなく、データの分位数に基づいてビンに分割します。

## 間隔ビニング(Interval Binning)
- 間隔ビニングは、データを等間隔のビンに分割する方法です。
- 間隔ビニングは、データの範囲を等間隔のビンに分割するため、データの分布を均等にすることができます。

## 　AWSはデフォルトで安全
- AWSは、デフォルトでセキュリティが強化されているため、セキュリティの設定を行わなくても安全に使用することができます。
- AWSは、デフォルトで暗号化、アクセス制御、監査ログなどのセキュリティ機能が提供されています。

## sagemakerにアタッチされたIAMロール
- デフォルトではsagemakerが名前に含まれたバケットへのS3アクセス権限がある

## LDA(Latent Dirichlet Allocation レイテント・ディリクレ配分)
- LDAは、トピックモデリングのための確率的生成モデルです。
  - トピックモデリング: テキストデータからトピック（テーマ）を抽出するための手法
- LDAは、文書を複数のトピックに分解し、各トピックが単語の確率分布を持つと仮定します。
- 膨大なデータセットの場合
  - データセットが大規模な場合、LDAのトレーニングに時間がかかる可能性があります。
  - RecordIO形式を使用することで、データの読み込み速度を向上させることができます。
    - RecordIO形式は、バイナリデータをシリアライズするためのフォーマットで、高速で効率的なデーエの読み書きを可能にします。
      - シリアライズ: データをバイト列に変換すること
  - パイプモードを使用することで、データの読み込み速度を向上させることができます。
    - パイプモード: データをバッチで読み込むことで、データの読み込み速度を向上させるモード

## ROC曲線(Receiver Operating Characteristic curve)
- ROC曲線は、分類モデルの性能を評価するための指標です。
- ROC曲線は、真陽性率（True Positive Rate）と偽陽性率（False Positive Rate）の関係を表します。
- ROC曲線のAUC（Area Under the Curve）は、分類モデルの性能を数値化するための指標です。
  - AUCが1に近いほど、モデルの性能が高いことを示します。
  - AUCとは、ROC曲線の下の面積を表す指標です。
  - AUCが0.5の場合、ランダムな予測と同等の性能を持つことを示します。

## Amazon Timestream
- Amazon Timestreamは、時系列データを保存、分析するためのデータベースサービスです。
- Amazon Timestreamを使用することで、大規模な時系列データを高速にクエリして分析することができます。

## エルボー法(Elbow Method) 
- エルボー法は、クラスタリングのためのハイパーパラメータの最適な値を見つけるための手法です。
- エルボー法は、クラスタの数Kを変化させながら、クラスタリングの性能を評価し、最適なクラスタの数を見つけることができます。
- k-means法のクラスタ数を決めるのに使える。
- クラスタリングはランダムにやるのではなく、エルボー法を使う！
- 合計二乗和（WSS=Within-Cluster Sum of Squares）が最も急激に減少する点をエルボーとして選択する
- グラフが肘のように曲がる点を選択するするためエルボー法（肘法）

## SMOTE(Synthetic Minority Over-sampling Technique)
- SMOTEは、不均衡なデータセットをオーバーサンプリングするための手法です。

## RecordIO形式とは
- RecordIO形式は、バイナリデータをシリアライズするためのフォーマットで、高速で効率的なデータの読み書きを可能にします。
- シリアライズとはデータをバイト列に変換すること。
- データの読み込み速度を向上させるために使用される。
- 複数の並列データを直列化して送信すること

## バッチサイズが大きいと
- 勾配が安定しているため、一度局所最適解に陥ると抜け出せなくなる。
  - 勾配が安定しているのは、バッチサイズが大きい=データが多いので、勾配を計算するデータが多くその平均を取るため

## AWS Direct Connect
- オンプレミスとAWSの間にプライベートネットワークを確立すること

## 運用上のオーバーヘッドとは
- 運用上のオーバーヘッドは、システムやサービスを運用するために必要な追加の作業やコストのことです。

## オーバーサンプリング
### ブートストラップ法
- ブートストラップ法は、データセットからランダムにサンプリングして、新しいデータセットを生成する手法です。
- ブートストラップ法は、オーバーサンプリングやアンダーサンプリングなどの不均衡データセットの処理に使用されます。
- オーバーサンプリングでは、少数派クラスのデータを増やすことで、データセットのバランスを取ることができます。
- 増やし方は既存のデータをコピーするのみ

### SMOTE法
- SMOTE法は、Synthetic Minority Over-sampling Techniqueの略で、不均衡なデータセットをオーバーサンプリングするための手法です。
- 新しいデータポイントを作成

## Amazon Macie(Macie=)
- Amazon Macieは、データの機密性やセキュリティを自動的に検出するためのサービスです。
- Amazon Macieを使用することで、データの機密性やセキュリティに関する問題を自動的に検出し、対処することができます。
- 機械学習とパターンマッチを使って、機密データを検出と保護をする


## AWS Panorama Appliance
- AWS Panorama Applianceは、ビジョンAI（Computer Vision）モデルをエッジデバイスで実行するためのデバイスです。
- AWS Panorama Applianceを使用することで、エッジデバイスでのビジョンAIモデルの実行を簡単に行うことができます。

## AWS Snowball edge
- AWS Snowball Edgeは、データの移行やエッジコンピューティングのためのデバイスです。
- AWS Snowball Edgeを使用することで、大規模なデータセットの移行やエッジコンピューティングの実行を簡単に行うことができます。

## Sagemaker Canvas
- Sagemaker Canvasは、機械学習モデルの開発とデバッグを行うためのツールです。
- Sagemaker Canvasを使用することで、機械学習モデルの開発プロセスを可視化し、デバッグすることができます。
- コード記述が必要なくMLモデルを作成できる


## Greengrass(=緑の草)
- AWS Greengrassは、エッジデバイスでのコンピューティングを実行するためのサービスです。
- AWS Greengrassを使用することで、エッジデバイスでのコンピューティングを簡単に実行することができます。

## ブルー/グリーンデプロイ
- ブルー/グリーンデプロイは、新しいバージョンのアプリケーションを展開する際に使用されるデプロイメント戦略です。
- ブルー/グリーンデプロイでは、新しいバージョンのアプリケーションを別の環境に展開し、問題がないことを確認した後、トラフィックを切り替えて新しいバージョンに移行します。

## A/Bテスト
- 複数のバリアント（モデルバージョン）を同じエンドポイントに登録
- 新規:既存 = 5:5や1:9の割合でトラフィックを振り分ける。1:9は新規のモデルでのリスクを減らしたいとき
- 一定期間後に結果を比較して、最適なバリアントを選択する

## カナリアリリース
- カナリアリリースは、新しいバージョンのアプリケーションを一部のユーザーに展開し、問題がないことを確認した後、全体に展開するデプロイメント戦略です。
- カナリアリリースでは、新しいバージョンのアプリケーションを一部のユーザーに展開し、問題がないことを確認した後、全体に展開するデプロイメント戦略です。
- カナリア=カナリア鳥のことで、炭鉱でガスを検知するために使用されていた=検査をするということ

## バリアントとは
- バリアントは、異なるバージョンや設定のアプリケーションを管理するための概念です。
- バリアントを使用することで、異なるバージョンや設定のアプリケーションを簡単に管理することができます。
- 複数のモデル=バリアント

## Elastic Beanstalk(Beanstalk=豆畑, 豆畑の様にスケーリングを行いやすい)
- Elastic Beanstalkは、アプリケーションのデプロイとスケーリングを簡単に行うためのサービスです。
- Elastic Beanstalkを使用することで、アプリケーションのデプロイとスケーリングを自動化し、運用コストを削減することができます。

## Sagemaker Experiments
- Sagemaker Experimentsは、機械学習モデルの実験を管理するための機能です。
- Sagemaker Experimentsを使用することで、機械学習モデルの実験を追跡し、比較することができます。

## AWS Glue Jobs
- AWS Glue Jobsは、データのETL（Extract, Transform, Load）処理を実行するためのジョブです。
- AWS Glue Jobsを使用することで、データの変換や統合を自動化し、データパイプラインを構築することができます。

## LDAアルゴリズム（Latent Dirichlet Allocation）
- LDAアルゴリズムは、トピックモデリングのための確率的生成モデルです。
- LDAアルゴリズムは、文書を複数のトピックに分解し、各トピックが単語の確率分布を持つと仮定します。
- トピックモデリングは、テキストデータからトピック（テーマ）を抽出するための手法です。
- 教師なし学習の一つ


## ACL(Access Control List)
- ACLは、ネットワークトラフィックの許可や拒否を制御するためのセキュリティグループのようなものです。
- ACLは、サブネットレベルで設定され、インバウンドとアウトバウンドのトラフィックを制御します。

## サブセット
- サブセットは、データセットの一部を抽出するための手法です。
- 標本抽出に近い

## EMRとGlueの違い
- EMRは、HadoopやSparkなどの分散処理フレームワークを実行するためのサービスです。
- Glueは、データのETL（Extract, Transform, Load）処理を行うためのサービスです。
- EMRはプロビジョニングが必要だが、Glueはサーバーレスである

## KNN
- KNN近傍方はあくまで推論

## k-means
- k-meansはクラスタリング

## SSL/TLS暗号化
- SSL/TLS暗号化は、データの暗号化を行うためのプロトコルです。
- SSL/TLS暗号化を使用することで、データの送信や受信を安全に行うことができます。
- SSL/TLS暗号化は、HTTPSなどのプロトコルで使用されています。
- アプリケーション層での暗号化です。

## Sagemaker Autopilot
- Sagemaker Autopilotは、機械学習モデルの自動生成を行うための機能です。
- Canvasの中に統合されていて、AutoMLの構築とデプロイのプロセスを自動化できる
- 入力形式はcsv, parquet
- jsonは不可能

## Stratified K-fold Cross Validation(層化K分割交差検証)
- Stratified K-fold Cross Validationは、データセットをK個のサブセットに分割し、各サブセットをテストセットとして使用する交差検証の手法です。
- Stratified K-fold Cross Validationは、データセットのクラスの分布を保持しながら、データセットを分割することができます。
- 要は元々のバランスを維持しながら層ごとに分割すること

## EBSとは（Elastic Block Store）
- EBSは、EC2インスタンスにアタッチされるブロックストレージのことです。
- EBSを使用することで、EC2インスタンスにデータを永続的に保存することができます。

## S3とは
- S3は、オブジェクトストレージサービスです。
- データレイクの構築やデータのバックアップ、アーカイブなどに使用されます。

## データレイクとは
- データレイクは、構造化データや非構造化データを保存、管理するためのデータストレージシステムです。
  
## Kinesis Data Streams (DMS)
- Kinesis Data Streamsは、ストリーミングデータをリアルタイムで処理するためのサービスです。
- DMSと略されることがある。
- 動画はストリーミングできないのでvideo streamを使う必要がある

## T-SNE(t-Distributed Stochastic Neighbor Embedding = t分布確率的近傍埋め込み)
- T-SNEは、高次元データを低次元データに変換するための手法です。
- T-SNEは、データの構造を保持しながら、データの可視化やクラスタリングを行うことができます。

## PCA(Principal Component Analysis = 主成分分析)
- PCAは、多次元データを低次元データに変換するための手法です。
- PCAは、データの次元削減や特徴量抽出を行うことができます。

## MICE(Multiple Imputation by Chained Equations = 連鎖方程式による多重代入)
- MICEは、欠損値を補完するための手法です。
- MICEは、欠損値を複数の変数に対して同時に補完することができます。

## 線形回帰でデータ補完
特徴間の線形関係を前提としているため、いつも当てはまるとは限らない

## KNN補完
- KNN補完は、K近傍法を使用して欠損値を補完するための手法です。
- 連続値データやカテゴリカルデータの補完に使用されます。

## リストワイズ削除
- リストワイズ削除は、欠損値を含む行を削除するための手法です。

## last observation carried forward（LOCF）
last observation carried forward（LOCF）は、欠損値を前の観測値で補完するための手法です。

## Inf2インスタンス(GPUちょっと)
- Inf2インスタンスは、機械学習モデルの推論やデータ分析などのワークロードに最適化されています。
- P3に比べると、コストが安い。ただし、性能は劣る。GPUは少し利用できる

## P3インスタンス(GPUがっつり)
- 大規模なGPUを使用して、機械学習モデルのトレーニングや推論を行うためのインスタンスです。
- sagemakerのseq2seqではGPUありきのインスタンスしかダメ

## c6gインスタンス（CPUメイン。コスト安い）
- c6gインスタンスは、ARMアーキテクチャを使用したインスタンスです。
- c6gインスタンスは、コストパフォーマンスが高く、機械学習やデータ分析などのワークロードに最適化されています。
- GPUは使用できない

## r6gインスタンス(RAMを多めに消費)
- r6gインスタンスは、ARMアーキテクチャを使用したインスタンスです。
- メモリ（RAM）を大量に消費するワークロードに最適化されています。



## A/Bテスト
- A/Bテストの場合は50:50の割合でトラフィックを振り分ける
- カナリアテストでは0:1で徐々に重みを更新

## sagemakerの組み込みアルゴリズム
- sagemakerの組み込みアルゴリズムは、決まったフレームワークが使用されているため自分で設定はできない。

## 非線形アルゴリズムとは
- 非線形アルゴリズムは、データの関係が線形でない場合に使用されるアルゴリズムです。
- 非線形アルゴリズムは、データの複雑な関係をモデル化するために使用されます。
- 線形アルゴリズムですでに残渣がうまくプロットされている場合は非線形アルゴリズムを利用する必要性はとくにない

## 線形学習アルゴリズム
- 回帰も分類も線形学習アルゴリズムで解決できる
- シンプル
- データが線形的に分離できる場合に有効

## 協調フィルタリング（Collaborative Filtering）
- 協調フィルタリングは、ユーザーの過去の行動や他のユーザーの行動を元に、アイテムの評価や推薦を行うための手法です。
- ユーザーの行動履歴を元にする。
- 類似ユーザーの行動を元にする

## コンテンツベースフィルタリング（Content-Based Filtering）
- コンテンツベースフィルタリングは、アイテムの特徴やユーザーの好みを元に、アイテムの評価や推薦を行うための手法です。
- コンテンツベースフィルタリングは、アイテムの特徴やユーザーの好みを元に、アイテムの評価や推薦を行います。

## Load Balancer
- Load Balancerは、トラフィックを複数のサーバーに分散するためのサービスです。
- Load Balancerを使用することで、サーバーの負荷を分散し、高可用性とスケーラビリティを実現することができます。
- ロードバランサーは、トラフィックを複数のサーバーに分散するためのサービスです。
- ロードバランサーを使用することで、サーバーの負荷を分散し、高可用性とスケーラビリティを実現することができます。
- sagemakerでは内部的にトラフィックを分散している。ロードバランサーは不要

## Kinesis FirehoseとData Streamsの違い
- Firehoseはストリームされたデータの形式を変換できるが、Data Streamsはできない
- Firehoseはすぐに保存、Data streamsは処理してから保存
- **オートスケーリングはFirehoseのみ**

### Firehose
- データ処理向上の様なイメージ
- Lambdaと統合されたデータ変換ができる
- データフロー: 例えばS3バケットへのデータ転送

## IP Insights
- Amazon Sagemaker IP Insight は、IP アドレスのリストを使用して、ユーザーの IP アドレスを分析し、不正なアクセスを検出するための機能です。
- 教師なし学習の一つ

## 画像系のアルゴリズム
### 画像分類アルゴリズム
- 画像分類アルゴリズムは、画像を異なるクラスに分類するためのアルゴリズムです。
- ラベルを特徴として学習する

### 物体検出アルゴリズム
- 物体検出アルゴリズムは、画像内の物体の位置とクラスを検出するためのアルゴリズムです。
- 物体の位置とクラスを検出する

### セグメンテーションアルゴリズム
- セグメンテーションアルゴリズムは、画像を異なる領域に分割するためのアルゴリズムです。
- 画像を異なる領域に分割する
- セマンティックセグメンテーションとインスタンスセグメンテーションがある
- ピクセルレベルで分類
  - セマンティックセグメンテーション: 画像を異なるクラスに分割する。環境**全体**のピクセル分類
  - インスタンスセグメンテーション: 画像内の物体の位置とクラスを検出する。物体ごとにピクセル単位で**個別で**分割（例: 3人の歩行者を個別に識別）

## グラフの偏り（skewed graph）
- 右に偏りがあるグラフとは、右側のテールが長いグラフのことです。左にデータが集まっています。
- 例えば、収入の分布や購買履歴などが右に偏っている場合があります。
- 左に偏りがあるグラフとは、左側のテールが長いグラフのことです。右にデータが集まっています。
- 例えば、テストの点数の分布などが左に偏っている場合があります。

## S3バケットの暗号化
S3 バケットは Amazon KMS を使用して保護されているため、ロールに S3 への読み取り権限を付与するだけでは不十分です。S3 のデータを復号化して読み取りを開始するには、KMS キーポリシー権限を付与する必要があります。


## パイプモード
- パイプモードを使用するとストリーミングでデータをトレーニングインスタンスに直接送信できるため、データの読み込み速度が向上します。
- 無料で使用できる

## AWS Data pipeline
- AWS Data Pipelineは、データ処理ワークフローを自動化するためのサービスです。
- AWS Data Pipelineを使用することで、データの移行、変換、処理を自動化し、データパイプラインを構築することができます。
- Glue との違いは、GlueはAapche Spack二に特化しており、AWSのリソース内で行われる。Data Pipelineは、オーケストレーションサービスでオンプレのデータなども扱える。コードなどのコントロールも可能。

## マネージドサービス
- マネージドサービスは、AWSがサービスの管理や運用を行うサービスのことです。
- マネージドサービスを使用することで、サービスの管理や運用にかかるコストやリスクを削減することができます。
- ETL自体は別サービスが必要

## データ拡張の利点
- データ拡張をするとトレーニングデータのランダム性が増え、オーバーフィッテイングに対処できる

## ウォームスタート　ハイパーパラメータ調整ジョブ
- ウォームスタートは、以前のハイパーパラメータ調整ジョブの結果を使用して、新しいハイパーパラメータ調整ジョブを開始するための機能です。

## 増分トレーニング
- モデルがすでに学習完了しているが、まだあまり推論性が良くない時に、新しいトレーニングデータで新しいモデルを訓練すること

## sagemkaer se1


## predicted class-frequency 
- 予測されたクラスの頻度（つまり予測されたラベルのうちそのクラスの割合はいくつか）

## True class-frequency
- 実際のクラスの頻度（つまりデータセット内にそのクラスの割合はいくつか）

## Accelerated computing family
- Accelerated Computing Family(=加速コンピューティングファミリー)は、GPUやFPGAなどのハードウェアを使用して、計算処理を加速するためのファミリーです。
- P3, G4, Inf2などのインスタンスが含まれます。
- P3インスタンスは、NVIDIA Tesla V100 GPUを使用して、機械学習やデータ分析などのワークロードに最適化されています。